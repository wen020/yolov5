{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb126728-7f74-44bf-b606-2215715295e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.ultralytics.com/zh/yolov5/tutorials/train_custom_data/#21-create-datasetyaml\n",
    "# https://drive.google.com/drive/folders/1svFSy2Da3cVMvekBwe13mzyx38XZ9xWo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86e3b40d-cddc-4cdc-a671-efeb6e69037d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing ./dataset/Detection/VOC2007/Annotations/IP087000986.xml: junk after document element: line 27, column 0\n",
      "0 101\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "classs = []\n",
    "def convert_annotation(xml_file, img_width, img_height):\n",
    "    try:\n",
    "        tree = ET.parse(xml_file)\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Error parsing {xml_file}: {e}\")\n",
    "        return []\n",
    "    root = tree.getroot()\n",
    "    yolo_annotations = []\n",
    "\n",
    "    for obj in root.findall('object'):\n",
    "        # 获取类别索引，减去 1 以适配 YOLOv5 的要求\n",
    "        class_id = int(obj.find('name').text)\n",
    "        \n",
    "        # 获取目标的边界框\n",
    "        bndbox = obj.find('bndbox')\n",
    "        xmin = int(bndbox.find('xmin').text)\n",
    "        ymin = int(bndbox.find('ymin').text)\n",
    "        xmax = int(bndbox.find('xmax').text)\n",
    "        ymax = int(bndbox.find('ymax').text)\n",
    "\n",
    "        # 转换为 YOLO 格式 (相对坐标)\n",
    "        x_center = (xmin + xmax) / 2 / img_width\n",
    "        y_center = (ymin + ymax) / 2 / img_height\n",
    "        width = (xmax - xmin) / img_width\n",
    "        height = (ymax - ymin) / img_height\n",
    "\n",
    "        classs.append(class_id)\n",
    "        # 添加到标注列表\n",
    "        yolo_annotations.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
    "    \n",
    "    return yolo_annotations\n",
    "\n",
    "def convert_dataset(image_dir, annotation_dir, output_image_dir, output_label_dir, image_set_file):\n",
    "    if not os.path.exists(output_image_dir):\n",
    "        os.makedirs(output_image_dir)\n",
    "    if not os.path.exists(output_label_dir):\n",
    "        os.makedirs(output_label_dir)\n",
    "    \n",
    "    with open(image_set_file, 'r') as f:\n",
    "        image_names = f.read().splitlines()\n",
    "\n",
    "    for image_name in image_names:\n",
    "        img_file = image_name + '.jpg'\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        img = Image.open(img_path)\n",
    "        img_width, img_height = img.size  # 获取图像宽度和高度\n",
    "\n",
    "        # 获取 XML 文件路径\n",
    "        xml_file = os.path.join(annotation_dir, image_name + '.xml')\n",
    "        \n",
    "        if os.path.exists(img_path) and os.path.exists(xml_file):\n",
    "            # 获取目标标注\n",
    "            yolo_annotations = convert_annotation(xml_file, img_width, img_height)\n",
    "\n",
    "            # 将图像复制到输出目录\n",
    "            shutil.copy(img_path, os.path.join(output_image_dir, img_file))\n",
    "\n",
    "            # 保存为 YOLO 格式的标注文件\n",
    "            txt_file = os.path.join(output_label_dir, image_name + '.txt')\n",
    "            with open(txt_file, \"w\") as f:\n",
    "                f.write(\"\\n\".join(yolo_annotations))\n",
    "\n",
    "# 设置路径\n",
    "image_dir = './dataset/Detection/VOC2007/JPEGImages'\n",
    "annotation_dir = './dataset/Detection/VOC2007/Annotations'\n",
    "output_image_dir_train = './IP102_YOLOv5/images/train'\n",
    "output_label_dir_train = './IP102_YOLOv5/labels/train'\n",
    "output_image_dir_val = './IP102_YOLOv5/images/val'\n",
    "output_label_dir_val = './IP102_YOLOv5/labels/val'\n",
    "\n",
    "# 训练集和验证集的文件路径\n",
    "trainval_file = './dataset/Detection/VOC2007/ImageSets/Main/trainval.txt'\n",
    "test_file = './dataset/Detection/VOC2007/ImageSets/Main/test.txt'\n",
    "\n",
    "# 处理训练集\n",
    "convert_dataset(image_dir, annotation_dir, output_image_dir_train, output_label_dir_train, trainval_file)\n",
    "\n",
    "# 处理测试集\n",
    "convert_dataset(image_dir, annotation_dir, output_image_dir_val, output_label_dir_val, test_file)\n",
    "\n",
    "print(min(classs),max(classs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fda56f3-62b7-44cc-b9a3-d25bd61e9ded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
